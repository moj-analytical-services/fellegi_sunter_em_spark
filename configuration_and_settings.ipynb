{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customising splink - configuration and settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In the [Quickstart demo](\"quickstart_demo.ipynb\") we saw an example of how to use `splink`.  There was minimal customisation of the settings - the demo relies on the fact that when settings are not specified by the user, `splink` uses sensible default values.  \n",
    "\n",
    "Not all settings have defaults - at minimum the user needs to choose the `link_type`, the `blocking_rules` and the `comparison_columns`.\n",
    "\n",
    "In most real-world applications, more accurate results will be obtained by customising the settings, often by trial and error. \n",
    "\n",
    "The main way to do this is through the `settings` dictionary.  This is passed to `splink` like so:\n",
    "\n",
    "\n",
    "```\n",
    "from splink import Splink\n",
    "\n",
    "settings = { }  # Settings dictionary goes here\n",
    "\n",
    "linker = Splink(settings, spark, df=df)\n",
    "```\n",
    "\n",
    "You can view 'sensible default' values that have been chosen for the other columns as follows:\n",
    "\n",
    "```\n",
    "from splink.settings import complete_settings_dict\n",
    "complete_settings_dict(settings)\n",
    "```\n",
    "\n",
    "This settings dictionary can be quite complicated, so this notebook provides details of the various settings and what they do.  \n",
    "\n",
    "We recommend using it alongside our [autocompleting settings editor](https://robinlinacre.com/simple_sparklink_settings_editor/), which makes it quicker and easier to write settings dictionaries.  This validates the your settings against the [json schema](https://github.com/moj-analytical-services/sparklink/blob/dev/sparklink/files/settings_jsonschema.json) for the settings.  Note: you can use this schema in some text editors to enable autocompletion - e.g. see [here](https://code.visualstudio.com/docs/languages/json#_intellisense-and-validation) for VS Code.\n",
    "\n",
    "\n",
    "\n",
    "You can also validate a settings object within Python with the following code:\n",
    "\n",
    "```\n",
    "from sparklink.validate import validate_settings\n",
    "validate_settings(settings)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the link type\n",
    "\n",
    "There are three types of data linking or deduplication built into `splink`, which are configured by setting the `link_type` key of the settings dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "The type of data linking task - `dedupe_only`, `link_only` or `link_and_dedupe`.  Required.\n",
       "\n",
       "**Description**:\n",
       "- When `dedupe_only`, the user provides a single input dataframe, and `splink` tries to find duplicate entries\n",
       "- When `link_only`, the user provides two dataframes, and `splink` tries to find a link between two two.  It makes no attempt to deduplicate datasets so this is best used when input datasets contain no duplicates\n",
       "- When `link_and_dedupe`, the user provides two dataframes, and `splink` simultanouesly links and dedupes the dataframes.\n",
       "\n",
       "**Data type**: string\n",
       "\n",
       "**Possible values**: `dedupe_only`, `link_only`, `link_and_dedupe`\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"link_type\": \"dedupe_only\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from demo_notebooks.demo_utils import render_key_as_markdown\n",
    "render_key_as_markdown(\"link_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing your blocking rules (or cartesian join)\n",
    "\n",
    "In most linking tasks, you will need to choose one or more [blocking rules](https://www.isi.edu/integration/papers/michelson06-aaai.pdf), which are used as a pre-processing step to eliminate implausible matches.  Without blocking, Apache Spark will compare all records to one another, which is usually computationally intractable (for linking problems of over about 10,000-50,000 records).  \n",
    "\n",
    "These are specified using the `blocking_rules` key of the `settings` dictionary.\n",
    "\n",
    "Alternatively, if you really do want to compare all records to one another, you can set the `cartesian_join` key instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "A list of one or more blocking rules to apply. Ignored if cartesian_product=true is set\n",
       "\n",
       "**Description**:\n",
       "Each rule is a SQL expression representing the blocking rule, which will be used to create a join.  The left table is aliased with `l` and the right table is aliased with `r`. For example, if you want to block on a `first_name` column, the blocking rule would be `l.first_name = r.first_name`.  Note that splink deduplicates the comparisons generated by the blocking rules.\n",
       "\n",
       "**Data type**: array\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"blocking_rules\": ['l.first_name = r.first_name AND l.surname = r.surname', 'l.dob = r.dob']\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from demo_notebooks.demo_utils import render_key_as_markdown\n",
    "render_key_as_markdown(\"blocking_rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartesian join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "If set to true, all comparisons between the input dataset(s) will be generated and blocking will not be used.\n",
       "\n",
       "**Description**:\n",
       "For large input datasets, the will generally be computationally intractable because it will generate comparisons equal to the number of rows squared.\n",
       "\n",
       "**Data type**: boolean\n",
       "\n",
       "**Default value if not provided**: False\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"cartesian_product\": False\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_key_as_markdown(\"cartesian_product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing which columns should be used to link data\n",
    "\n",
    "The user must decide which columns in the input datasets will be used to link data.  \n",
    "\n",
    "For example, if the user is deduplicating a table of people, it would be typical to use personal identifiers like name and date of birth.\n",
    "\n",
    "These columns, and configuration options for each individual column, are provided as a list of dictionaries assigned to the `comparison_columns` key of the `settings` dictionary.\n",
    "\n",
    "At a minimum, each entry in the list must have `column_name` populated.  All other settings have sensible defaults.\n",
    "\n",
    "For example:\n",
    "```\n",
    "settings = {\n",
    "    \"comparison_columns\": [\n",
    "    {\n",
    "        \"column_name\": \"first_name\"\n",
    "    },\n",
    "    {\n",
    "        \"column_name\": \"latitude\",\n",
    "        \"data_type\": \"numeric\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "**Note that, throughout the splink package, it is assumed that incoming datasets have been prepared so they have common column names - e.g. if you are linking two datasets on first name, the column containing this data has the same name in both datasets.  This cannot be configured and the package will not work without this preparation step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a prior for proportion of matches\n",
    "\n",
    "`splink` is more likely to iterate towards good parameter values if the starting values are good guesses.  An important setting is `proportion_of_matches`, which is the starting value (prior belief) for the proportion of comparisons which are matches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "The proportion of comparisons thought to be matches\n",
       "\n",
       "**Description**:\n",
       "This provides the initial value (prior) that EM algorithm will start iterating from\n",
       "\n",
       "**Data type**: number\n",
       "\n",
       "**Default value if not provided**: 0.3\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"proportion_of_matches\": 0.3\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_key_as_markdown(\"proportion_of_matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring individual columns\n",
    "\n",
    "Each entry in the `comparison_columns` list is a dictionary, which enables the user to provide additional customisation options for each individual comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "The number of different similarity levels that will be computed for this column\n",
       "\n",
       "**Description**:\n",
       "A greater value for `num_levels` means the algorithm can be more precise about how string similarity is treated - e.g. by making a distinction between strings which are an almost-exact match, strings which are quite similar, and strings which don't really match at all.  However, more levels results in longer compute times and can sometimes affect convergence. By default, for a string variable, two levels would implies level 0: no match, level 1: almost exact match.  Three levels imples level 0: no match, level 1: strings are similar but not exactly the same, level 2: strings are almost exactly the same.\n",
       "\n",
       "**Data type**: integer\n",
       "\n",
       "**Default value if not provided**: 2\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"comparison_columns: [\n",
       "    {\n",
       "        \"num_levels\": 2\n",
       "    }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_key_as_markdown(\"num_levels\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "The data type of the column.  This is used to choose how similarity is assessed this column. This is ignored if you explicitly provide a case_expression.\n",
       "\n",
       "**Description**:\n",
       "- If `string` is specified, `splink` will use the Jaro Winkler string comparison functions.\n",
       "- If `numeric` is specified, then similarity will be assessed based on the absolute percentage difference between the two values.\n",
       "\n",
       "**Data type**: string\n",
       "\n",
       "**Possible values**: `string`, `numeric`\n",
       "\n",
       "**Default value if not provided**: string\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"comparison_columns: [\n",
       "    {\n",
       "        \"data_type\": \"string\"\n",
       "    }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from demo_notebooks.demo_utils import render_key_as_markdown\n",
    "render_key_as_markdown(\"data_type\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency adjustments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Description**:\n",
       "Whether ex post term frequency adjustments should be made to match scores for this column\n",
       "\n",
       "**Data type**: boolean\n",
       "\n",
       "**Default value if not provided**: False"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_key_as_markdown(\"term_frequency_adjustments\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**:\n",
       "A SELECT CASE expression that compares the values of the input column and returns integer values corresponding to num_levels. \n",
       "\n",
       "**Description**:\n",
       "This is an override which allows the user to cusomise how similarity is computed for this column.  If given, this overrides the default mechanism of comparing columns and ignores data_type\n",
       "\n",
       "**Data type**: string\n",
       "\n",
       "**Example**:\n",
       "\n",
       "```\n",
       "settings = {\n",
       "    \"comparison_columns: [\n",
       "    {\n",
       "        \"case_expression\": \"CASE WHEN first_name_l = first_name_r THEN 1 ELSE 0 END\"\n",
       "    }\n",
       "]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_key_as_markdown(\"case_expression\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a full settings dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"proportion_of_matches\": 0.6,\n",
    "    \"blocking_rules\": [\n",
    "        \"l.first_name = r.first_name AND l.surname = r.surname\",\n",
    "        \"l.dob = r.dob AND l.surname = r.surname\"\n",
    "    ],\n",
    "    \"comparison_columns\": [\n",
    "        {\n",
    "        \"col_name\": \"first_name\",\n",
    "        \"num_levels\": 3,\n",
    "        \"term_frequency_adjustments\": true\n",
    "        },\n",
    "        {\n",
    "        \"col_name\": \"surname\",\n",
    "        \"num_levels\": 3,\n",
    "        \"term_frequency_adjustments\": true\n",
    "        },\n",
    "        {\n",
    "        \"col_name\": \"date_of_birth\",\n",
    "        \"case_expression\": \"CASE WHEN l.date_of_birth = r.date_of_birth THEN 2 WHEN year(l.date_of_birth) = year(r.date_of_bitth) THEN 1 ELSE 0 END\"\n",
    "        },\n",
    "        {\n",
    "        \"col_name\": \"income_gbp\",\n",
    "        \"data_type\": \"numeric\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
