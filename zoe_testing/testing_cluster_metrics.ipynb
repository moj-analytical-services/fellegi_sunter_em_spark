{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "from splink.duckdb.blocking_rule_library import block_on, exact_match_rule\n",
    "from splink.duckdb.comparison_library import (\n",
    "    exact_match,\n",
    "    levenshtein_at_thresholds,\n",
    ")\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "df = splink_datasets.fake_1000\n",
    "\n",
    "\n",
    "settings = {\n",
    "    \"probability_two_random_records_match\": 0.01,\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on([\"first_name\"]),\n",
    "        exact_match_rule(\"surname\"),\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        levenshtein_at_thresholds(\"first_name\", 2),\n",
    "        exact_match(\"surname\"),\n",
    "        exact_match(\"dob\"),\n",
    "        exact_match(\"city\", term_frequency_adjustments=True),\n",
    "        exact_match(\"email\"),\n",
    "    ],\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"additional_columns_to_retain\": [\"cluster\"],\n",
    "    \"max_iterations\": 10,\n",
    "    \"em_convergence\": 0.01,\n",
    "}\n",
    "\n",
    "\n",
    "linker = DuckDBLinker(df, settings)\n",
    "\n",
    "# linker.profile_columns(\n",
    "#     [\"first_name\", \"surname\", \"first_name || surname\", \"concat(city, first_name)\"]\n",
    "# )\n",
    "\n",
    "\n",
    "linker.estimate_u_using_random_sampling(target_rows=1e6)\n",
    "\n",
    "\n",
    "blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "linker.estimate_parameters_using_expectation_maximisation(blocking_rule)\n",
    "\n",
    "\n",
    "blocking_rule = \"l.dob = r.dob\"\n",
    "linker.estimate_parameters_using_expectation_maximisation(blocking_rule)\n",
    "\n",
    "\n",
    "df_predict = linker.predict()\n",
    "df_clustered = linker.cluster_pairwise_predictions_at_threshold(df_predict, 0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>n_edges</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>989</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>993</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>997</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>528 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster_id  n_nodes  n_edges   density\n",
       "0             0        2      1.0  1.000000\n",
       "1             1        2      1.0  1.000000\n",
       "2             4        2      1.0  1.000000\n",
       "3             6        1      0.0       NaN\n",
       "4             7        1      0.0       NaN\n",
       "..          ...      ...      ...       ...\n",
       "523         989        1      0.0       NaN\n",
       "524         991        1      0.0       NaN\n",
       "525         992        1      0.0       NaN\n",
       "526         993        4      5.0  0.833333\n",
       "527         997        3      3.0  1.000000\n",
       "\n",
       "[528 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = linker._compute_cluster_metrics(df_predict, df_clustered, threshold_match_probability=0.9)\n",
    "metrics.as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.unique_id_concat import (\n",
    "    _composite_unique_id_from_nodes_sql,\n",
    ")\n",
    "uid_cols = linker._settings_obj._unique_id_input_columns\n",
    "composite_uid_clusters = _composite_unique_id_from_nodes_sql(uid_cols)\n",
    "type(composite_uid_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add source dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that person_id is not unique across datasets\n",
    "So make  a new unique id for person from the unique_id and the source_dataset fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from splink.duckdb.duckdb_comparison_library import (\n",
    "    exact_match,\n",
    ")\n",
    "from splink.duckdb.duckdb_linker import DuckDBLinker\n",
    "\n",
    "settings = {\n",
    "    \"probability_two_random_records_match\": 0.01,\n",
    "    # \"link_type\": \"link_only\",\n",
    "    \"link_type\": \"link_and_dedupe\",\n",
    "    \"comparisons\": [\n",
    "        exact_match(\"first_name\"),\n",
    "        exact_match(\"surname\"),\n",
    "        exact_match(\"dob\"),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "}\n",
    "\n",
    "\n",
    "df_1 = [\n",
    "    {\"unique_id\": 1, \"first_name\": \"Tom\", \"surname\": \"Fox\", \"dob\": \"1980-01-01\"},\n",
    "    {\"unique_id\": 2, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "    {\"unique_id\": 3, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "    {\"unique_id\": 4, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "    {\"unique_id\": 5, \"first_name\": \"Bob\", \"surname\": \"Ray\", \"dob\": \"1999-09-22\"},\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "df_2 = [\n",
    "    {\"unique_id\": 1, \"first_name\": \"Bob\", \"surname\": \"Ray\", \"dob\": \"1999-09-22\"},\n",
    "    {\"unique_id\": 2, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "\n",
    "]\n",
    "\n",
    "df_1 = pd.DataFrame(df_1)\n",
    "df_2 = pd.DataFrame(df_2)\n",
    "\n",
    "linker = DuckDBLinker(\n",
    "    [df_1, df_2], settings, input_table_aliases=[\"df_left\", \"df_right\"]\n",
    ")\n",
    "\n",
    "# linker = DuckDBLinker(df_1, settings)\n",
    "\n",
    "\n",
    "df_predict = linker.predict()\n",
    "display(df_predict.as_pandas_dataframe())\n",
    "\n",
    "df_clustered = linker.cluster_pairwise_predictions_at_threshold(df_predict, 0.9)\n",
    "display(df_clustered.as_pandas_dataframe().sort_values(\"cluster_id\"))\n",
    "\n",
    "linker.debug_mode = True\n",
    "df_result = linker._compute_cluster_metrics(df_predict, df_clustered, 0.9).as_pandas_dataframe()\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_result.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 10\n",
    "n_edges = 1\n",
    "\n",
    "density = (n_edges * 2)/(n_nodes * (n_nodes-1))\n",
    "density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = linker._settings_obj._unique_id_input_columns\n",
    "\n",
    "print(cols)\n",
    "\n",
    "# unique_id_col = linker._settings_obj._unique_id_column_name\n",
    "# unique_id_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.unique_id_concat import _composite_unique_id_from_edges_sql\n",
    "from splink.input_column import InputColumn\n",
    "\n",
    "\n",
    "uid_cols = linker._settings_obj._unique_id_input_columns\n",
    "# unique_id = InputColumn(unique_id_col)\n",
    "# source_dataset = InputColumn(\"source_dataset\")\n",
    "# unique_id_col_l = input_col.name_l\n",
    "\n",
    "uid_edges_l = _composite_unique_id_from_edges_sql(uid_cols, \"l\")\n",
    "\n",
    "uid_edges_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating test from dedupe to dedupe and link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from splink.duckdb.duckdb_comparison_library import (\n",
    "    exact_match,\n",
    ")\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "\n",
    "df_1 = [\n",
    "    {\"unique_id\": 1, \"first_name\": \"Tom\", \"surname\": \"Fox\", \"dob\": \"1980-01-01\"},\n",
    "    {\"unique_id\": 2, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "    {\"unique_id\": 3, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "]\n",
    "\n",
    "df_2 = [\n",
    "    {\"unique_id\": 1, \"first_name\": \"Bob\", \"surname\": \"Ray\", \"dob\": \"1999-09-22\"},\n",
    "    {\"unique_id\": 2, \"first_name\": \"Amy\", \"surname\": \"Lee\", \"dob\": \"1980-01-01\"},\n",
    "]\n",
    "\n",
    "df_1 = pd.DataFrame(df_1)\n",
    "df_2 = pd.DataFrame(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function insides\n",
    "from IPython.display import display\n",
    "\n",
    "settings = {\n",
    "    \"probability_two_random_records_match\": 0.01,\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"comparisons\": [\n",
    "        exact_match(\"first_name\"),\n",
    "        exact_match(\"surname\"),\n",
    "        exact_match(\"dob\"),\n",
    "    ],\n",
    "}\n",
    "linker = DuckDBLinker(df_1, settings)\n",
    "\n",
    "df_predict = linker.predict()\n",
    "df_clustered = linker.cluster_pairwise_predictions_at_threshold(df_predict, 0.9)\n",
    "\n",
    "df_result = linker._compute_cluster_metrics(\n",
    "    df_predict, df_clustered, threshold_match_probability=0.9\n",
    ").as_pandas_dataframe()\n",
    "display(df_result)\n",
    "\n",
    "data_expected = [\n",
    "    {\"cluster_id\": 1, \"n_nodes\": 1, \"n_edges\": 0.0, \"density\": None},\n",
    "    {\"cluster_id\": 2, \"n_nodes\": 2, \"n_edges\": 1.0, \"density\": 1.0},\n",
    "]\n",
    "df_expected = pd.DataFrame(data_expected)\n",
    "display(df_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedupe test\n",
    "\n",
    "\n",
    "def test_size_density_dedupe():\n",
    "    # Linker with basic settings\n",
    "    settings = {\n",
    "        \"probability_two_random_records_match\": 0.01,\n",
    "        \"link_type\": \"dedupe_only\",\n",
    "        \"comparisons\": [\n",
    "            exact_match(\"first_name\"),\n",
    "            exact_match(\"surname\"),\n",
    "            exact_match(\"dob\"),\n",
    "        ],\n",
    "    }\n",
    "    linker = DuckDBLinker(df_1, settings)\n",
    "\n",
    "    df_predict = linker.predict()\n",
    "    df_clustered = linker.cluster_pairwise_predictions_at_threshold(df_predict, 0.9)\n",
    "\n",
    "    df_result = linker._compute_cluster_metrics(\n",
    "        df_predict, df_clustered, threshold_match_probability=0.9\n",
    "    ).as_pandas_dataframe()\n",
    "\n",
    "    data_expected = [\n",
    "        {\"cluster_id\": 1, \"n_nodes\": 1, \"n_edges\": 0.0, \"density\": None},\n",
    "        {\"cluster_id\": 2, \"n_nodes\": 2, \"n_edges\": 1.0, \"density\": 1.0},\n",
    "    ]\n",
    "    df_expected = pd.DataFrame(data_expected)\n",
    "\n",
    "    assert_frame_equal(df_result, df_expected, check_index_type=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_density_dedupe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function insides - link_only\n",
    "from IPython.display import display\n",
    "\n",
    "settings = {\n",
    "    \"probability_two_random_records_match\": 0.01,\n",
    "    \"link_type\": \"link_only\",\n",
    "    \"comparisons\": [\n",
    "        exact_match(\"first_name\"),\n",
    "        exact_match(\"surname\"),\n",
    "        exact_match(\"dob\"),\n",
    "    ],\n",
    "}\n",
    "linker = DuckDBLinker(\n",
    "    [df_1, df_2], settings, input_table_aliases=[\"df_left\", \"df_right\"]\n",
    ")\n",
    "\n",
    "linker.debug_mode=True\n",
    "\n",
    "df_predict = linker.predict()\n",
    "df_clustered = linker.cluster_pairwise_predictions_at_threshold(df_predict, 0.9)\n",
    "\n",
    "df_result = (\n",
    "    linker._compute_cluster_metrics(\n",
    "        df_predict, df_clustered, threshold_match_probability=0.99\n",
    "    )\n",
    "    .as_pandas_dataframe()\n",
    "    .sort_values(by=\"cluster_id\")\n",
    ")\n",
    "\n",
    "display(df_result)\n",
    "\n",
    "data_expected = [\n",
    "    {\n",
    "        \"cluster_id\": \"df_left-__-1\",\n",
    "        \"n_nodes\": 1,\n",
    "        \"n_edges\": 0.0,\n",
    "        \"density\": None,\n",
    "    },\n",
    "    {\n",
    "        \"cluster_id\": \"df_left-__-2\",\n",
    "        \"n_nodes\": 3,\n",
    "        \"n_edges\": 2.0,\n",
    "        \"density\": 0.666667,\n",
    "    },\n",
    "    {\n",
    "        \"cluster_id\": \"df_right-__-1\",\n",
    "        \"n_nodes\": 1,\n",
    "        \"n_edges\": 0.0,\n",
    "        \"density\": None,\n",
    "    },\n",
    "]\n",
    "df_expected = pd.DataFrame(data_expected).sort_values(by=\"cluster_id\")\n",
    "display(df_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link test\n",
    "\n",
    "\n",
    "def test_size_density_link():\n",
    "    # Linker with basic settings\n",
    "    settings = {\n",
    "        \"probability_two_random_records_match\": 0.01,\n",
    "        \"link_type\": \"link_only\",\n",
    "        \"comparisons\": [\n",
    "            exact_match(\"first_name\"),\n",
    "            exact_match(\"surname\"),\n",
    "            exact_match(\"dob\"),\n",
    "        ],\n",
    "    }\n",
    "    linker = DuckDBLinker(\n",
    "        [df_1, df_2], settings, input_table_aliases=[\"df_left\", \"df_right\"]\n",
    "    )\n",
    "\n",
    "    df_predict = linker.predict()\n",
    "    df_clustered = linker.cluster_pairwise_predictions_at_threshold(df_predict, 0.9)\n",
    "\n",
    "    df_result = linker._compute_cluster_metrics(\n",
    "        df_predict, df_clustered, threshold_match_probability=0.99\n",
    "    ).as_pandas_dataframe().sort_values(by='cluster_id')\n",
    "\n",
    "    data_expected = [\n",
    "        {\n",
    "            \"cluster_id\": \"df_left-__-1\",\n",
    "            \"n_nodes\": 1,\n",
    "            \"n_edges\": 0.0,\n",
    "            \"density\": None,\n",
    "        },\n",
    "        {\n",
    "            \"cluster_id\": \"df_right-__-1\",\n",
    "            \"n_nodes\": 1,\n",
    "            \"n_edges\": 0.0,\n",
    "            \"density\": None,\n",
    "        },\n",
    "        {\n",
    "            \"cluster_id\": \"df_left-__-2\",\n",
    "            \"n_nodes\": 3,\n",
    "            \"n_edges\": 2.0,\n",
    "            \"density\": 0.666667,\n",
    "        },\n",
    "    ]\n",
    "    df_expected = pd.DataFrame(data_expected).sort_values(by='cluster_id')\n",
    "\n",
    "    assert_frame_equal(df_result, df_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_density_link()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test general functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splink-bxsLLt4m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
