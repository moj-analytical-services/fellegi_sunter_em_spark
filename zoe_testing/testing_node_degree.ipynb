{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and linker set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up linker\n",
    "\n",
    "# Simple dummy df\n",
    "person_ids = [i + 1 for i in range(6)]\n",
    "df = pd.DataFrame({\"person_id\": person_ids})\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"unique_id_column_name\": \"person_id\",\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "}\n",
    "linker = DuckDBLinker(df, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trialing on simple dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up edges, clusters and cluster metrics tables\n",
    "\n",
    "# Dummy edges df\n",
    "person_ids_l = [1, 1, 4, 6, 12]\n",
    "person_ids_r = [2, 3, 5, 11, 13]\n",
    "match_probabilities = [0.99, 0.99, 0.99, 0.80, 0.95]\n",
    "\n",
    "edges_data = {\n",
    "    \"match_probability\": match_probabilities,\n",
    "    \"person_id_l\": person_ids_l,\n",
    "    \"person_id_r\": person_ids_r,\n",
    "}\n",
    "edges = pd.DataFrame(edges_data)\n",
    "\n",
    "# Dummy clusters df\n",
    "cluster_ids = [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\"]\n",
    "clusters_data = {\"cluster_id\": cluster_ids, \"person_id\": person_ids}\n",
    "clusters = pd.DataFrame(clusters_data)\n",
    "\n",
    "df_predict = linker.register_table(edges, \"df_predict\", overwrite=True)\n",
    "df_clustered = linker.register_table(clusters, \"df_clustered\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composite_unique_id</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>node_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   composite_unique_id cluster_id  node_degree\n",
       "1                    1          A            2\n",
       "2                    2          A            1\n",
       "3                    3          A            1\n",
       "0                    4          B            1\n",
       "5                    5          B            1\n",
       "4                    6          C            0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing node metrics - working as expected\n",
    "\n",
    "linker._compute_metrics_nodes(\n",
    "    df_predict, df_clustered, threshold_match_probability=0.9\n",
    ").as_pandas_dataframe().sort_values('cluster_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>n_edges</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster_id  n_nodes  n_edges   density\n",
       "0          A        3      2.0  0.666667\n",
       "1          B        2      1.0  1.000000\n",
       "2          C        1      0.0       NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing size, density, centralisation metrics - working\n",
    "\n",
    "# linker.debug_mode=True\n",
    "\n",
    "df_node_metrics = linker._compute_metrics_nodes(\n",
    "    df_predict, df_clustered, threshold_match_probability=0.9\n",
    ")\n",
    "\n",
    "linker._compute_metrics_clusters(df_node_metrics).as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = linker._compute_cluster_metrics(df_predict, df_clustered, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>n_edges</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cluster_id  n_nodes  n_edges   density\n",
       "0          A        3      2.0  0.666667\n",
       "1          B        2      1.0  1.000000\n",
       "2          C        1      0.0       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = dictionary[\"clusters\"]\n",
    "df_out.as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on historical 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_hist = pd.read_csv(\"clusters_hist_50k.csv\")\n",
    "edges_hist = pd.read_csv(\"edges_hist_50k.csv\")\n",
    "\n",
    "# Update linker unique id to match data\n",
    "linker._settings_obj._unique_id_column_name = \"unique_id\"\n",
    "\n",
    "# Convert to splink dataframes\n",
    "df_predict = linker.register_table(edges_hist, \"df_predict\", overwrite=True)\n",
    "df_clustered = linker.register_table(clusters_hist, \"df_clustered\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing node metrics - runs\n",
    "\n",
    "linker._compute_metrics_nodes(\n",
    "    df_predict, df_clustered, threshold_match_probability=0.9\n",
    ").as_pandas_dataframe().sort_values(\"cluster_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing size, density, centralisation metrics - working\n",
    "\n",
    "# linker.debug_mode=True\n",
    "\n",
    "df_node_metrics = linker._compute_metrics_nodes(\n",
    "    df_predict, df_clustered, threshold_match_probability=0.9\n",
    ")\n",
    "\n",
    "linker._compute_metrics_clusters(df_node_metrics).as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Nomis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up edges and clusters data\n",
    "\n",
    "edges_nomis = pd.read_csv(\"nomis_edges_anonymised.csv\")\n",
    "# edges_nomis[\"person_id_l\"] = edges_nomis[\"person_id_l\"].astype(int)\n",
    "clusters_nomis = pd.read_csv(\"nomis_clusters_anonymised.csv\")\n",
    "\n",
    "# Give cols conventional names\n",
    "# Change cluster_low to cluster_x for threshold x\n",
    "clusters_nomis = clusters_nomis.rename(columns={\"cluster_low\": \"cluster_id\"})\n",
    "\n",
    "# Transform to Splink dataframes\n",
    "df_edges_nomis = linker.register_table(edges_nomis, \"edges_nomis\", overwrite=True)\n",
    "df_clusters_nomis = linker.register_table(\n",
    "    clusters_nomis, \"clusters_nomis\", overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node degree - working\n",
    "\n",
    "linker._compute_metrics_nodes(\n",
    "    df_edges_nomis, df_clusters_nomis, threshold_match_probability=0.9\n",
    ").as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing size, density, centralisation metrics - working\n",
    "\n",
    "# linker.debug_mode=True\n",
    "\n",
    "df_node_metrics = linker._compute_metrics_nodes(\n",
    "    df_edges_nomis, df_clusters_nomis, threshold_match_probability=0.9\n",
    ")\n",
    "\n",
    "linker._compute_metrics_clusters(df_node_metrics).as_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try generating the clusters data again from nomis edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.debug_mode = False\n",
    "\n",
    "nomis_predict = pd.read_csv(\"nomis_edges_anonymised.csv\")\n",
    "# nomis_predict[\"person_id_l\"] = nomis_predict[\"person_id_l\"].astype(int)\n",
    "# nomis_predict[\"person_id_r\"] = nomis_predict[\"person_id_r\"].astype(int)\n",
    "\n",
    "\n",
    "# Transform to Splink dataframes\n",
    "df_nomis_predict = linker.register_table(nomis_predict, \"nomis_predict\", overwrite=True)\n",
    "\n",
    "new_nomis_clusters = linker.cluster_pairwise_predictions_at_threshold(\n",
    "    df_nomis_predict, 0.9\n",
    ")\n",
    "display(new_nomis_clusters.as_pandas_dataframe().sort_values(\"cluster_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.cluster_studio_dashboard(\n",
    "    df_edges_nomis,\n",
    "    df_clusters_nomis,\n",
    "    out_path=\"cluster_studio.html\",\n",
    "    sampling_method=\"by_cluster_density\",\n",
    "    sample_size=10,\n",
    "    overwrite=True,\n",
    "    _df_cluster_metrics=df_cluster_metrics_nomis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should these have selects in them though?\n",
    "\n",
    "\n",
    "def _centralisation_sql():\n",
    "    sql = f\"SELECT stuff FROM {df_node_metrics.physical_name}\"\n",
    "    sql = {\"sql\": sql, \"output_table_name\": \"__splink__counts_per_cluster\"}\n",
    "    return sql\n",
    "\n",
    "\n",
    "def _density_sql():\n",
    "    sql = f\"SELECT stuff FROM __splink_centralisation\"\n",
    "    sql = {\"sql\": sql, \"output_table_name\": \"__splink__cluster_metrics_clusters\"}\n",
    "    return sql\n",
    "\n",
    "\n",
    "def linker_method():\n",
    "    sql = _centralisation_sql()\n",
    "    self._enqueue_sql(sql[\"sql\"], sql[\"output_table_name\"])\n",
    "    sql = _density_sql()\n",
    "    self._enqueue_sql(sql[\"sql\"], sql[\"output_table_name\"])\n",
    "\n",
    "    df_cluster_metrics = self._execute_sql_pipeline()\n",
    "    return df_cluster_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _centralisation_sql(\n",
    "    df_node_metrics: SplinkDataFrame,\n",
    ") -> List[Dict[str, str]]:\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            cluster_id,\n",
    "            COUNT(*) AS n_nodes,\n",
    "            SUM(node_degree)/2.0 AS n_edges,\n",
    "            MAX(node_degree) AS max_degree,\n",
    "            CASE\n",
    "                WHEN COUNT(*) > 2 THEN\n",
    "                    1.0*(COUNT(*) * MAX(node_degree) -  SUM(node_degree)) /\n",
    "                    ((COUNT(*) - 1) * (COUNT(*) - 2))\n",
    "                ELSE\n",
    "                    NULL\n",
    "            END AS cluster_centralisation\n",
    "        FROM {df_node_metrics.physical_name}\n",
    "        GROUP BY\n",
    "            cluster_id\n",
    "    \"\"\"\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building actual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splink.cluster_studio import _get_cluster_id_by_density\n",
    "\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "\n",
    "# Dummy df and settings for linker\n",
    "person_ids = [i + 1 for i in range(5)]\n",
    "df = pd.DataFrame({\"person_id\": person_ids})\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"unique_id_column_name\": \"person_id\",\n",
    "}\n",
    "linker = DuckDBLinker(df, settings)\n",
    "\n",
    "# Dummy cluster metrics table\n",
    "cluster = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "n_nodes = [3, 2, 10, 3, 19]\n",
    "n_edges = [2, 1, 5, 2, 25]\n",
    "density = [\n",
    "    (n_edges * 2) / (n_nodes * (n_nodes - 1))\n",
    "    for n_nodes, n_edges in zip(n_nodes, n_edges)\n",
    "]\n",
    "df_metrics = pd.DataFrame(\n",
    "    {\"cluster_id\": cluster, \"n_nodes\": n_nodes, \"n_edges\": n_edges, \"density\": density}\n",
    ")\n",
    "df_metrics\n",
    "\n",
    "# Convert to Splink dataframe\n",
    "df_cluster_metrics = linker.register_table(\n",
    "    df_metrics, \"df_cluster_metrics\", overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing this function\n",
    "\n",
    "def _get_cluster_id_by_density(\n",
    "    linker, df_cluster_metrics, sample_size: int, min_nodes: int\n",
    "):\n",
    "    # Ordering: least dense clusters first\n",
    "    sql = f\"\"\"\n",
    "    SELECT cluster_id\n",
    "    FROM {df_cluster_metrics.physical_name}\n",
    "    WHERE n_nodes >= {min_nodes}\n",
    "    ORDER BY density\n",
    "    LIMIT {sample_size}\n",
    "    \"\"\"\n",
    "\n",
    "    df_density_sample = linker._sql_to_splink_dataframe_checking_cache(\n",
    "        sql, \"__splink__density_sample\"\n",
    "    )\n",
    "\n",
    "    return [r[\"cluster_id\"] for r in df_density_sample.as_record_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = _get_cluster_id_by_density(linker, df_cluster_metrics, sample_size=3, min_nodes=3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better to put the linker inside the function?\n",
    "\n",
    "def test_density_sample():\n",
    "    df_result = _get_cluster_id_by_density(\n",
    "        linker, df_cluster_metrics, sample_size=3, min_nodes=3\n",
    "    )\n",
    "    df_expect = [\"C\", \"E\", \"A\"]\n",
    "    assert df_result == df_expect\n",
    "\n",
    "test_density_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_size_density():\n",
    "    # Linker with basic settings\n",
    "    settings = {\"link_type\": \"dedupe_only\", \"unique_id_column_name\": \"person_id\"}\n",
    "    linker = DuckDBLinker(df, settings)\n",
    "\n",
    "    # Register as Splink dataframes\n",
    "    df_predict = linker.register_table(edges, \"df_predict\", overwrite=True)\n",
    "    df_clustered = linker.register_table(clusters, \"df_clustered\", overwrite=True)\n",
    "\n",
    "    df_cluster_metrics = linker._compute_cluster_metrics(\n",
    "        df_predict, df_clustered, threshold_match_probability=0.99\n",
    "    )\n",
    "    df_cluster_metrics = df_cluster_metrics.as_pandas_dataframe()\n",
    "\n",
    "    assert_frame_equal(df_cluster_metrics, df_expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splink-bxsLLt4m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
