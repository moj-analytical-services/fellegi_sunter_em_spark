{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig()\n",
    "\n",
    "# logging.getLogger(\"sql\").setLevel(\"DEBUG\")\n",
    "# logging.getLogger(\"gammas\").setLevel(\"DEBUG\")\n",
    "# logging.getLogger(\"expectation_step\").setLevel(\"DEBUG\")\n",
    "# logging.getLogger(\"maximisation_step\").setLevel(\"DEBUG\")\n",
    "# logging.getLogger(\"comparison_evaluation\").setLevel(\"DEBUG\")\n",
    "# logging.getLogger(\"sparklink\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import StructType\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "# WARNING:\n",
    "# These config options are appropriate only if you're running Spark locally!!!\n",
    "conf=SparkConf()\n",
    "conf.set('spark.driver.memory', '8g')\n",
    "conf.set(\"spark.sql.shuffle.partitions\", \"8\") \n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparklink.sql import *\n",
    "from sparklink.blocking import *\n",
    "from sparklink.gammas import *\n",
    "from sparklink.params import *\n",
    "from sparklink.expectation_step import *\n",
    "from sparklink.maximisation_step import *\n",
    "from sparklink.iterate import *\n",
    "from sparklink.comparison_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data/data_null.csv\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comparison = cartestian_block(df, spark=spark)\n",
    "\n",
    "blocking_rules = []\n",
    "\n",
    "blocking_rules.append('l.surname = r.surname')\n",
    "blocking_rules.append('l.mob = r.mob')\n",
    "\n",
    "\n",
    "df_comparison = block_using_rules(df, blocking_rules, spark=spark)\n",
    "\n",
    "df_comparison = df_comparison.withColumn(\"label\", (df_comparison[\"group_l\"]==df_comparison[\"group_r\"]).cast(\"int\"))\n",
    "\n",
    "df_comparison.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_settings = {\n",
    "    \"mob\": {\n",
    "        \"levels\": 2\n",
    "    },\n",
    "    \"surname\": {\n",
    "        \"levels\": 3\n",
    "    }}\n",
    "\n",
    "df_gammas = add_gammas(df_comparison, gamma_settings, spark, include_orig_cols = True)\n",
    "df_gammas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "params = Params(gamma_settings, starting_lambda=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# print(json.dumps(params.params, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = sql_gen_gamma_prob_columns(params)\n",
    "\n",
    "df_gammas.registerTempTable(\"df_with_gamma\")\n",
    "df_with_gamma_probs = spark.sql(sql)\n",
    "df_with_gamma_probs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_gamma_probs.registerTempTable(\"df_with_gamma_probs\")\n",
    "sql = sql_gen_expected_match_prob(params)\n",
    "\n",
    "df_e = spark.sql(sql)\n",
    "df_e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's saying that for each row where surname_l == surname_r, compute the proportion of matches and non-matches\n",
    "\n",
    "df_e.registerTempTable(\"df_e\")\n",
    "\n",
    "sql = \"\"\"\n",
    "select surname_l, surname_r, sum(match_probability) mp, sum(1-match_probability) as nmp\n",
    "from df_e\n",
    "where surname_l = surname_r\n",
    "group by surname_l, surname_r\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "surname_lookup = spark.sql(sql)\n",
    "surname_lookup.show()\n",
    "surname_lookup.registerTempTable(\"surname_lookup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "select *, coalesce(mp/(mp+nmp), {params.params[\"Î»\"]}) as pseudo_lambda\n",
    "from df_e as e \n",
    "left join\n",
    "surname_lookup as s\n",
    "on s.surname_l = e.surname_l\n",
    "and s.surname_l = e.surname_r\n",
    "\"\"\"\n",
    "df_e_adj = spark.sql(sql)\n",
    "df_e_adj.registerTempTable(\"df_e_adj\")\n",
    "\n",
    "sql = \"\"\"\n",
    "select *, (pseudo_lambda * prob_gamma_0_match * prob_gamma_1_match) /((pseudo_lambda * prob_gamma_0_match * prob_gamma_1_match) + ((1-pseudo_lambda) * prob_gamma_0_non_match * prob_gamma_1_non_match)) as adjusted_exp\n",
    "from \n",
    "df_e_adj\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
